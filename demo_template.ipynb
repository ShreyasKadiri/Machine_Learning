{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6bsscvgYXpkStrmEoDOi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyasKadiri/Machine_Learning/blob/main/demo_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvRHPR02GQ6T"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "sns.set()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMUjcP7oHbJI"
      },
      "source": [
        "#Load the data\n",
        "df = pd.read_csv(‘file.csv’)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "b_wDQPoSGUMo",
        "outputId": "d37f8ca8-9b9c-4d2b-dc58-be97ccfb8880"
      },
      "source": [
        "#Visualize data\n",
        "df.head()\n",
        "df.describe()\n",
        "df.info()\n",
        "df.columns\n",
        "\n",
        "#For a categorical dataset we want to see how many instances of each category there are\n",
        "df['categorical_var'].value_counts()                                                \n",
        "\n",
        "#Exploratory Data Analysis (EDA)\n",
        "sns.pairplot(df)\n",
        "sns.distplot(df['column'])\n",
        "sns.countplot(df['column'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d9d1acd7de99>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df = pd.read_csv(‘file.csv’)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID-OqdpuIp5i"
      },
      "source": [
        "#Data pre-processing\n",
        "\n",
        "#Fix or remove outliers\n",
        "plt.boxplot(df['feature1'])\n",
        "plt.boxplot(df['feature2'])\n",
        "\n",
        "\n",
        "#Check for missing data\n",
        "total_null = df.isna().sum().sort_values(ascending=False)\n",
        "percent = (df.isna().sum()/df.isna().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total_null, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "\n",
        "#Generate new features with missing data\n",
        "df['feature1_nan'] = df['feature1'].isna()\n",
        "df['feature2_nan'] = df['feature2'].isna()\n",
        "\n",
        "\n",
        "#Also look for infinite data, recommended to check it also after feature engineering\n",
        "df.replace(np.inf,0,inplace=True)\n",
        "df.replace(-np.inf,0,inplace=True)\n",
        "\n",
        "\n",
        "#Check for duplicated data\n",
        "df.duplicated().value_counts()\n",
        "df['duplicated'] = df.duplicated() #Create a new feature\n",
        "\n",
        "\n",
        "#Fill missing data or drop columns/rows\n",
        "df.fillna()\n",
        "df.drop('column_full_of_nans')\n",
        "df.dropna(how='any')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_6sF_t2Ix2c"
      },
      "source": [
        "#Model selection and evaluation\n",
        "\n",
        "#Define Validation method\n",
        "#Train and validation set split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('target_var', inplace=True, axis=1)\n",
        "y = df['column to predict']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.4, stratify = y.values, random_state = 101)\n",
        "\n",
        "#Cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "#StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, random_state=101)\n",
        "for train_index, val_index in skf.split(X, y):\n",
        "  X_train, X_val = X[train_index], X[val_index]\n",
        "  y_train, y_val = y[train_index], y[val_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY-Y0EneJXh8"
      },
      "source": [
        "#########\n",
        "# Random Forest\n",
        "#########\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor(n_estimators=200, random_state=101, n_jobs=-1, verbose=3)\n",
        "rfr.fit(X_train, y_train)\n",
        "#Use model to predict\n",
        "y_pred = rfr.predict(X_val)\n",
        "#Evaluate accuracy of the model\n",
        "acc_rf = round(rfr.score(X_val, y_val) * 100, 2)\n",
        "#Evaluate feature importance\n",
        "importances = rfr.feature_importances_\n",
        "std = np.std([importances for tree in rfr.estimators_], axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "feature_importances = pd.DataFrame(rfr.feature_importances_, index = X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
        "feature_importances.sort_values('importance', ascending=False)\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RygGHKOjJoTT"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
        "grid = GridSearchCV(model, param_grid, verbose = 3)\n",
        "grid.fit(X_train, y_train)\n",
        "grid.best_params_\n",
        "grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}